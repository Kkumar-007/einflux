# einflux
ðŸŒ€ einflux â€“ Because tensors deserve a little chaos.

> _Effortlessly reshape reality... or at least your tensors._

**einflux** is a chaotic-good tensor rearrangement library inspired by [`einops`](https://github.com/arogozhnikov/einops). It's fast, flexible, and built for people who think dimension manipulation should feel more like casting spells than writing code.

---

## ðŸš€ Mission

I tried to **re-implement `einops` from scratch**, and... mission accomplished!  
The core idea was to rebuild the functionality, parsing, and reshaping logic from the ground up using just **NumPy**.

> While this version works great and supports a wide range of rearrangement patterns, benchmarks show that it's currently **~2.51x slower** than the original `einops` library. Totally expected for a first version â€“ and hey, it's readable!

---

## âœ¨ Features

- ðŸ” **Pattern-based dimension sorcery** â€“ Write rearrange logic as readable strings like `"a b c -> c a b"`
- ðŸ§© **Split & merge dimensions** â€“ Do `(a b) c -> a (b c)` like it's nothing
- ðŸŽ­ **Wildcard & ellipsis support** â€“ Use `*` or `...` to match variable dims
- ðŸ” **Smart dimension inference** â€“ Forget hardcoding sizes, we gotchu
- âš¡ **Fast & memory-friendly** â€“ Powered by NumPyâ€™s vectorized magic
- ðŸ§¼ **Solid error handling** â€“ Clear feedback when patterns go ðŸ’¥

---

## ðŸ§  Pattern Syntax Cheat Sheet

```python
"a b c -> c a b"       # Transpose
"(a b) c -> a (b c)"   # Split then merge
"a * b -> b * a"       # Wildcard match
"a ... b -> b ... a"   # Ellipsis life
"(a 2) b -> b (2 a)"   # Fixed numeric dimensions
```

---

##âš™ï¸ Design Decisions

- ðŸš€ **One-pass parser for patterns** â€“ fast and less annoying
- ðŸ§  **Inference engine that auto-fills unknown dims** - like a mind-reader
- ðŸ§½ **Memory efficient reshapes/transposes** â€“ no unnecessary copies
- ðŸ’¥ **Errors that make sense** â€“ so you donâ€™t cry when things break

---

##ðŸ§ª How to Run
###ðŸ§¬ Basic Usage
```python
import numpy as np
from rearrange import rearrange

x = np.zeros((2, 3, 4))

# Rearrange example
result = rearrange(x, "a b c -> c a b")
print(result.shape)  # (4, 2, 3)

# Splitting dimensions
x = np.zeros((6, 4))
result = rearrange(x, "(a b) c -> a (b c)", a=2, b=3)
print(result.shape)  # (2, 12)
```

ðŸ§ª Running Tests
```python
import unittest

# Run all tests
unittest.main(argv=['first-arg-is-ignored'], exit=False)

# Or run a specific test class
unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(TestRearrange))
```

---

##âš¡ Performance Vibes
- Built with NumPy for ðŸ”¥ speed
- Pattern parsing optimized in a single-pass
- Efficient dimension inference without slowing you down
- Clean error handling with zero BS

##ðŸ“‰ Benchmark Report:
I ran performance comparisons between einflux and the original einops library across various tensor sizes and rearrangement patterns.

On average, einflux is ~2.51x slower than einops.

This performance difference is expected due to the additional parsing logic and lack of low-level optimization in the current prototype. Future versions aim to narrow this gap while maintaining readability and flexibility.

ðŸ“ The full performance report is included in the repo: performance_report.md

---

##ðŸ§µ Edge Cases? We Handle Those Too
- âœ… Repeated dimensions in output like a b -> a b a
- âœ… Mixing numbers and names (a 2) b -> b (2 a)
- âœ… Wildcards and ellipses like a champ
- âœ… Smart validation that tells you whatâ€™s wrong

---

##ðŸ“¦ Installation
Not on PyPI yet. Just clone this:

```bash
git clone https://github.com/Kkumar-007/einflux.git
cd einflux
```

---

##ðŸ˜Ž License
MIT â€“ steal it, modify it, launch it into production, just donâ€™t blame me when your tensors ascend to a higher dimension.

---

##ðŸ’¬ Contributing
Got ideas? Bugs? Cool pattern syntax? Open a PR or start an issue. Tensor wizards welcom
